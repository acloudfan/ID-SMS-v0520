{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Understand data's readiness for ML and Prepare it for ML\n",
    "\n",
    "#### 0. Read the CSV data file\n",
    "#### 1. Data Distribution\n",
    "#### 2. Correlation Analysis    \n",
    "#### 3. Frequency Distribution (Categorical features)\n",
    "#### 4. Frequency Distribution (Numerical features)\n",
    "#### 5. Data prep for XGBoost\n",
    "#### 6. Split the data into training, validation and testing\n",
    "#### 7. Upload the data files to S3\n",
    "\n",
    "\n",
    "<b>How will we do it?</b>\n",
    "- Use Pandas for reading the data\n",
    "- Use Matplotlib for visualization\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "## 0. Read the Data file </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the appropriate packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# This is to get the root location\n",
    "home_folder=os.environ.get('HOME','/root')\n",
    "data_folder = \"{}/SMID/1-data-cleanup-and-prep\".format(home_folder)\n",
    "data_file = \"churn-dataset-with-header.csv\"\n",
    "\n",
    "data_file_path = data_folder + \"/\" + data_file\n",
    "\n",
    "print(\"Reading the data from: {}\".format(data_file_path))\n",
    "# Read the data\n",
    "churn = pd.read_csv(data_file_path)\n",
    "\n",
    "# This will display sample data; label column = 'Churn?'  A value of True indicates that customer churned!!!\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# 1. Data Analysis | Distribution\n",
    "    \n",
    "* Look for features that you think will NOT play any role in the churn prediction. Those features will be dropped. Some such features may be obvious *but* for some you may need assistance from the business SME.\n",
    "* Certain features that have a numeric representation but have no order can mislead the ML algorithms and that mess up the accuracy. Look for such fields. Such fields may be either dropped if they are not relevant or the type of such fields need to be changed to non-numeric.\n",
    "* Even distribution is desired to minimize the bias *but* it may not be the case all the time. There are many techniques to address this issue. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stats for the fields - uncomment the line below to checkout the data\n",
    "# display(churn.describe())\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ct = round((churn[churn[\"Churn?\"]==\"True.\"].count()[\"Churn?\"] * 100)/churn[\"Churn?\"].count(),2)\n",
    "print(\"Churn Distribution  - True frequency={}%\".format(ct))\n",
    "churn['Churn?'].value_counts().plot(kind='bar',figsize=(5,5))\n",
    "plt.show()\n",
    "\n",
    "# State Distribution\n",
    "print(\"State Distribution\")\n",
    "churn['State'].value_counts().plot(kind='bar',figsize=(25,5))\n",
    "plt.show()\n",
    "\n",
    "# Histograms for each numeric features\n",
    "true_count=churn[\"Churn?\"]\n",
    "\n",
    "\n",
    "print(\"Numeric Fields Distribution\")\n",
    "hist = churn.hist(bins=30, sharey=True, figsize=(10, 10))\n",
    "\n",
    "## Uncomment below to see the data - Frequency tables for each categorical feature\n",
    "# for column in churn.select_dtypes(include=['object']).columns:\n",
    "#     display(pd.crosstab(index=churn[column], columns='% observations', normalize='columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "### Results of Distribution Analysis\n",
    "1. State appears to be quite evenly distributed; skewness can be problematic as it can lead to higher bias\n",
    "\n",
    "2. Only 14% of customers churned, so there is some class imabalance, but *nothing extreme*; Imabalanced data sets lead to BAD predictions but we are fine as imbalance is NOT extreme.\n",
    "\n",
    "3. Phone takes on too many unique values to be of any practical use. \n",
    "\n",
    "4. Area Code showing up as a numeric feature we should\n",
    "\n",
    "<strong>ðŸ’¡ DROP the 'Phone' feature as it doesn't play a role in customer's decision</strong>\n",
    "    \n",
    "<strong>ðŸ’¡ Change the 'Area Code' field type to non-numeric </strong></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP the Phone as it does NOT play any role in the Churning\n",
    "churn = churn.drop('Phone', axis=1)\n",
    "\n",
    "# CHANGE the type of 'Area Code'\n",
    "churn['Area Code'] = churn['Area Code'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# 2. Correlation | Relationship analysis\n",
    "That is, we are going to check which features have an impact on whether the customer is at the risk of churn or not.\n",
    "- Pandas Cross tabs are a quick way to checkout the correlation between the field and the label\n",
    "- To read checkout the churn True-frequency against the value of the attribute\n",
    "\n",
    "We need to lookout for the features that have 100% correlation. It can easily be done by plotting scatter matrix. Please be patient as these graphs take time to plot. For larger data sets it may not be even feasible.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and plot the correlation between fields\n",
    "display(churn.corr())\n",
    "pd.plotting.scatter_matrix(churn, figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "### Result of correlation analysis\n",
    "Following features have 100% correlation with some of the other fields\n",
    "* Day Charge   -    Day Min\n",
    "* Eve Charge   -    Eve Min\n",
    "* Night Charge -    Night Min\n",
    "* Intl Charge  -    Intl Min\n",
    "\n",
    "ðŸ’¡ <strong>DROP the fields 'Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DROP the fields 'Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'\n",
    "churn = churn.drop(['Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "# 3. Frequency Analysis (Categorical Features)\n",
    "Plot the counts of Churn?=True | Churn?=False and try to understand the relationship.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Analysis \n",
    "for column in churn.select_dtypes(include=['object']).columns:\n",
    "    if column != 'Churn?':\n",
    "#         display(pd.crosstab(index=churn[column], columns=churn['Churn?'], normalize='columns'))\n",
    "        pd.crosstab(index=churn[column], columns=churn['Churn?'], normalize='columns').plot(kind='bar',figsize=(10,10))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Results of Frequency Analysis (Categorical Features)\n",
    "\n",
    "<strong>ðŸ’¡ Churners are fairly evenly distributed geographically</strong>\n",
    "    \n",
    "<strong>ðŸ’¡ Churners are MORE likely to have an international plan</strong>\n",
    "    \n",
    "<strong>ðŸ’¡ Churners LESS likely to have a voicemail plan</strong></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "# 4. Frequency Analysis (Numerical Features)\n",
    "Plot the counts of Churn?=True | Churn?=False and try to understand the relationship.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the following two lines to checkout the data\n",
    "#     if column != 'Churn?':\n",
    "#         display(pd.crosstab(index=churn[column], columns=churn['Churn?'], normalize='columns'))\n",
    "for column in churn.select_dtypes(exclude=['object']).columns:\n",
    "    print(column)\n",
    "    hist = churn[[column, 'Churn?']].hist(by='Churn?', bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "### Results of Frequency Analysis (Numerical Features)\n",
    "\n",
    "<strong>ðŸ’¡ Churners have a larger number of customer service calls (which makes sense as we'd expect customers who experience lots of problems may be more likely to churn)</strong>\n",
    "    \n",
    "<strong>ðŸ’¡ Churners exhibit some bimodality in daily minutes (either higher or lower than the average for non-churners)</strong></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "    \n",
    "# 5. Preparing the data for ML Algo (XGBoost)\n",
    "At this time our data is Clean *BUT* it is not yet ready to be consumed by ML algorithms. Each algo requires the data in certain format. We will be using XGBoost so we need to ensure the following:\n",
    "\n",
    "* Data is in either CSV or LibSVM format\n",
    "* The categorical columns need to be \"One Hot Encoded\" i.e., numerical representation \n",
    "* The prediction column or Label MUST be in the first column\n",
    "* The HEADER shouldn't be there\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE - Categorical var42614261aws batch\n",
    "model_data = pd.get_dummies(churn)\n",
    "\n",
    "# Add the 'Churn?' column to the begining \n",
    "model_data = pd.concat([model_data['Churn?_True.'], model_data.drop(['Churn?_False.', 'Churn?_True.'], axis=1)], axis=1)\n",
    "\n",
    "\n",
    "# train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9 * len(model_data))])\n",
    "# train_data.to_csv('train.csv', header=False, index=False)\n",
    "# validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "    \n",
    "### 6. Split the data into training, validation and testing\n",
    "\n",
    "* training     90%      train.csv\n",
    "* validation   10%      validation.csv\n",
    "* testing      10%      test.csvc\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9 * len(model_data))])\n",
    "train_data.to_csv(data_folder+'/'+'train.csv', header=False, index=False)\n",
    "validation_data.to_csv(data_folder+'/'+'validation.csv', header=False, index=False)\n",
    "test_data.to_csv(data_folder+'/'+'test.csv', header=False, index=False)\n",
    "\n",
    "# Used for local model evaluation in a later exercise - ignore at this time\n",
    "test_data.to_csv('test_header.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "    \n",
    "### 7. Upload the data files to S3\n",
    "    \n",
    "The Machine Learning Training Jobs reads the data from S3 buckets and writes the models to the S3 Buckets. Before executing the next step. <code style=\"background:yellow;color:black\">You MUST create an S3 Bucket</code>\n",
    "\n",
    "You may create the bucket in many ways:\n",
    "\n",
    "- Use the AWS Console\n",
    "- Use the AWS CLI\n",
    "- Use the Boto3/SDK\n",
    "\n",
    "In this step we need to create the S3 bucket that we will use through the rest of this exercise. Decide on the name of the bucket you will create. My suggestion - name your bucket using the scheme below:\n",
    "\n",
    "<code style=\"background:yellow;color:black\">*[First Name]-[Last-4-Digit-of-Your-Phone-Number]*</code>\n",
    "\n",
    "S3 bucket name MUST be unique across AWS so if you run into name collision then adjust the name e.g., by adding a '-1' at end or using your house number instead of phone number ... be creative but make the name easy to remember :)\n",
    "\n",
    "#### Steps - Create the Bucket from Terminal\n",
    "1. Open a new terminal File > New > Terminal\n",
    "2. Run the Command\n",
    "    * aws s3api create-bucket --bucket <code style=\"background:yellow;color:black\">[Replace this for Bucket-Name]</code> --region us-east-1\n",
    "3. Confirm by executing the command\n",
    "    * aws s3api list-buckets\n",
    "4. Close the terminal\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 bucket using the console\n",
    "# MUST change this to point to your bucket\n",
    "bucket = \"awsrajeev\"\n",
    "\n",
    "# This will be a folder created under your bucket \n",
    "# Do NOT change this\n",
    "prefix = \"sagemaker/churn-analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uploads the CSV files to S3\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, \"train/train.csv\")).upload_file(data_folder+'/'+'train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, \"validation/validation.csv\")).upload_file(data_folder+'/'+'validation.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, \"test/test.csv\")).upload_file(data_folder+'/'+'test.csv')\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'raw/churn-dataset-with-header.csv')).upload_file(data_folder+'/'+'churn-dataset-with-header.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"> \n",
    "\n",
    "### IMPORTANT\n",
    "If you made changes to the notebook or if there are errors. \n",
    "\n",
    "* Un comment the code in the next block \n",
    "* Run the cell; this will pick up the files from under the data-files folder and upload to the S3\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IGNORE this cell\n",
    "## IF (A) you did not change the code in this notebook (B) you were able to execute the notebook without any errors\n",
    "\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, \"train/train.csv\")).upload_file(data_folder+'/'+'data-files/train.csv')\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, \"validation/validation.csv\")).upload_file(data_folder+'/'+'data-files/validation.csv')\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, \"test/test.csv\")).upload_file(data_folder+'/'+'data-files/test.csv')\n",
    "\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'raw/churn-dataset-with-header.csv')).upload_file(data_folder+'/'+'churn-dataset-with-header.csv')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
### Data Preparation & Training
Clearly the data provided to you needs some massaging. There are multiple tools available for fixing the data. The decision on which tool to use will depend on multiple factors especially the volume. Most seasoned data scientists during the experimentation phase use small sets of data to test out the models. The processing of these smaller sets of data does not require any sophisticated tools as they can easily be managed in Jupyter Notebooks.

Remember that ML exercise is iterative so you may need to carry out this task multiple times and scripted pre-processing of data in Jupyter Notebooks make the Data Scientists very productive.  

Train the model a couple of times using different sets of Hyperparameters. Pay attention to the metrics generated by the algorithms. You will need to make a decision on which training job produced the best results. The Training job that produced the best results will be used in the next step i.e., deploying the model.